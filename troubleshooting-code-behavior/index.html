<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Linux HA Docs" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Troubleshooting code behavior - Linux HA and Virtualization</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Troubleshooting code behavior";
        var mkdocs_page_input_path = "troubleshooting-code-behavior.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Linux HA and Virtualization
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Cluster Technologies</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../cluster/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cluster/corosync/">Corosync</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cluster/pacemaker/">Pacemaker</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Virtualization</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../virtualization/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../virtualization/qemu/">QEMU</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../virtualization/kvm/">KVM</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../virtualization/libvirt/">libvirt</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../virtualization/virsh/">virsh</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../virtualization/ovs/">Open vSwitch</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Storage</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../storage/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../storage/ceph/">CEPH</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../storage/iscsi/">iSCSI</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../storage/nvme-of/">NVMe-oF</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../storage/gfs2/">GFS2</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Network</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../network/libvirt-network/">libvirt Networking</a>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../reference/">Reference</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../deployment/">Deployment</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../resources/">Resources</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../license/">License</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Linux HA and Virtualization</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Troubleshooting code behavior</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/CrakA2/Linux_HA/edit/master/docs/troubleshooting-code-behavior.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="troubleshooting-code-behavior-and-diagnostics">Troubleshooting Code Behavior and Diagnostics</h2>
<p>This section provides comprehensive guidance on diagnosing and resolving issues with clustering, virtualization, and storage technologies from a code behavior perspective.</p>
<h3 id="debugging-techniques">Debugging Techniques</h3>
<h4 id="enable-debug-logging">Enable Debug Logging</h4>
<p><strong>Corosync:</strong>
<pre class="highlight"><code class="language-bash"># Enable debug mode in corosync.conf
logging {
    to_logfile: yes
    logfile: /var/log/corosync/corosync.log
    debug: on
    debug_logfile: /var/log/corosync/debug.log
}

# Or use cormapctl
corosync-cmapctl totem.debug = 1
corosync-cmapctl totem.logging_debug = 1</code></pre></p>
<p><strong>Pacemaker:</strong>
<pre class="highlight"><code class="language-bash"># Enable verbose logging
crm_simulate --live-check
crm_simulate --show-failcounts
crm_simulate --showscores

# Check detailed resource actions
pcs resource show-status

# Monitor CIB changes
crm_mon --show-detail
crm_mon --show-node-attributes</code></pre></p>
<p><strong>QEMU/KVM:</strong>
<pre class="highlight"><code class="language-bash"># Enable QEMU debug output
qemu-system-x86_64 -d in_asm,op,exec,cpu_reset,guest_errors,int,mmu

# QMP debugging
qemu-system-x86_64 -qmp stdio -monitor stdio

# Enable KVM debug
echo 1 &gt; /sys/module/kvm/parameters/debug
echo 1 &gt; /sys/module/kvm_intel/parameters/debug
echo 1 &gt; /sys/module/kvm_amd/parameters/debug</code></pre></p>
<p><strong>Ceph:</strong>
<pre class="highlight"><code class="language-bash"># Enable debug logging
ceph config set global debug_msgr 10
ceph config set mon debug_mon 10

# Enable object logging
ceph config set global debug_filestore 20
ceph config set global debug_rados 20

# Monitor OSD operations
ceph tell osd.0 dump_ops</code></pre></p>
<h3 id="common-code-level-issues">Common Code-Level Issues</h3>
<h4 id="corosync-issues">Corosync Issues</h4>
<p><strong>1. Token Circulation Problems</strong></p>
<pre class="highlight"><code>Symptoms:
- Nodes unable to send messages
- Token stuck on one node
- Messages delayed excessively

Causes:
- Network partition
- Token timeout too short
- Network buffer overflow

Diagnosis:
corosync-cfgtool -s
corosync-quorumtool -s

Check token status:
corosync-cmapctl runtime.totem.token

Check ring state:
corosync-cmapctl runtime.totem.token_hold_time</code></pre>
<pre class="highlight"><code>Solution:</code></pre>
<h1 id="increase-token-timeout">Increase token timeout</h1>
<p>totem {
    token: 10000           # Increase from default 10000
    token_retransmit: 500
}</p>
<h1 id="reduce-network-traffic">Reduce network traffic</h1>
<p>totem {
    window_size: 50        # Reduce from default 100
    max_messages: 17
}</p>
<h1 id="check-network-configuration">Check network configuration</h1>
<p>ping -c 3 <target-host>
tcpdump -i any 'port 5405'
<pre class="highlight"><code>
**2. Quorum Failures**
</code></pre>
Symptoms:
- Cluster loses quorum
- Nodes operate independently
- Resources stop responding</p>
<p>Diagnosis:
corosync-quorumtool -s</p>
<p>Check expected vs actual votes
Check node connectivity
<pre class="highlight"><code></code></pre>
Solution:
<pre class="highlight"><code># Verify network connectivity
ping -c 5 &lt;all-cluster-nodes&gt;

# Check Corosync communication
corosync-cfgtool -s

# Adjust quorum settings
nodelist {
    node {
        quorum_votes: 3
    }
}

# Ensure proper node count
# Use odd number of nodes for majority</code></pre></p>
<h4 id="pacemaker-issues">Pacemaker Issues</h4>
<p><strong>1. Resource Start Failures</strong></p>
<pre class="highlight"><code>Symptoms:
- Resources stuck in "Starting" state
- Resources fail to start repeatedly
- CRM crashes or restarts

Diagnosis:
pcs status

Check resource status:
pcs resource show-status resource-name

Check CRM logs:
journalctl -u pacemaker -n 50 | less

Check transition history:
crm_history --show</code></pre>
<pre class="highlight"><code>Solution:</code></pre>
<h1 id="increase-operation-timeout">Increase operation timeout</h1>
<p>pcs resource op add resource-name start \
    timeout=60s interval=0s on-fail=restart</p>
<h1 id="check-resource-agent">Check resource agent</h1>
<p>pcs resource debug-resource resource-name
crm_resource --validate --resource resource-name</p>
<h1 id="check-for-configuration-errors">Check for configuration errors</h1>
<p>crm_verify -L -V
<pre class="highlight"><code>
**2. Constraint Violations**
</code></pre>
Symptoms:
- Resources not placed according to constraints
- Unexpected resource placement
- Colocation not respected</p>
<p>Diagnosis:
pcs constraint show --full</p>
<p>Check constraint scores:
crm_simulate --showscores</p>
<p>Verify constraint definitions:
pcs constraint order list
pcs constraint colocation list
<pre class="highlight"><code></code></pre>
Solution:
<pre class="highlight"><code># Verify constraints are correct
pcs constraint order list
pcs constraint colocation list

# Adjust constraint scores
pcs constraint order set order-id \
    symmetrical=false

# Clear broken constraints
pcs constraint remove constraint-id

# Recalculate cluster state
pcs resource cleanup</code></pre></p>
<p><strong>3. Resource Agent Bugs</strong></p>
<pre class="highlight"><code>Symptoms:
- OCF agent returns invalid status codes
- Agent timeout during start/stop
- Agent crashes

Diagnosis:
# Test agent manually
ocf_resource:ocf:heartbeat:IPaddr2 monitor

# Check agent logs
grep "resource-name" /var/log/pacemaker/pengine/*

# Validate agent syntax
crm_resource --validate --resource resource-name</code></pre>
<pre class="highlight"><code>Solution:</code></pre>
<h1 id="test-agent-manually">Test agent manually</h1>
<p>export OCF_ROOT=/usr/lib/ocf/resource.d/heartbeat
/usr/lib/ocf/resource.d/heartbeat/IPaddr2 monitor
OCF_RESKEY=OCF_ROOT=/usr/lib/ocf/resource.d/heartbeat</p>
<h1 id="update-agent-operation-timeout">Update agent operation timeout</h1>
<p>pcs resource op add resource-name start \
    timeout=120s</p>
<h1 id="monitor-agent-behavior">Monitor agent behavior</h1>
<p>pcs resource op monitor resource-name \
    timeout=30s interval=10s</p>
<h1 id="use-standard-agents-if-possible">Use standard agents if possible</h1>
<h1 id="ensure-ocf-compliant-agents">Ensure OCF-compliant agents</h1>
<p><pre class="highlight"><code>
#### QEMU/KVM Issues

**1. VM Startup Failures**
</code></pre>
Symptoms:
- VM fails to boot
- Kernel panic in guest
- No console output</p>
<p>Diagnosis:
qemu-system-x86_64 -d in_asm,cpu_reset</p>
<h1 id="check-vm-configuration">Check VM configuration</h1>
<p>virsh dumpxml vm-name</p>
<h1 id="monitor-qmp-events">Monitor QMP events</h1>
<p>echo '{"execute":"qmp_capabilities"}' | \
    socat UNIX-CONNECT:/var/run/libvirt/qemu/vm-name.monitor
<pre class="highlight"><code></code></pre>
Solution:
<pre class="highlight"><code># Simplify VM configuration
virt-install --name vm1 --memory 1024 --vcpus 1

# Disable problematic features
qemu-system-x86_64 -no-hpet -no-acpi

# Use different machine type
virt-install --name vm1 --machine pc

# Check disk image integrity
qemu-img check disk.qcow2

# Enable serial console
qemu-system-x86_64 -serial pty -monitor stdio</code></pre></p>
<p><strong>2. Performance Issues</strong></p>
<pre class="highlight"><code>Symptoms:
- VM runs slowly
- High CPU usage on host
- Poor I/O performance

Diagnosis:
# Monitor host CPU
top -H -p qemu-system-x86_64

# Check KVM configuration
lsmod | grep kvm

# Monitor VM internals
virsh qemu-monitor-command vm-name "info status"

# Check disk I/O
iotop -o -a

# Check network I/O
iftop -i br0</code></pre>
<pre class="highlight"><code>Solution:</code></pre>
<h1 id="enable-kvm">Enable KVM</h1>
<p>qemu-system-x86_64 -enable-kvm</p>
<h1 id="use-virtio-drivers">Use virtio drivers</h1>
<p>virt-install --disk bus=virtio --network model=virtio</p>
<h1 id="enable-virtio-multiqueue">Enable virtio multiqueue</h1>
<p>virt-install --cpu host-passthrough,cache=writeback</p>
<h1 id="tune-scheduler">Tune scheduler</h1>
<p>echo 1 &gt; /sys/module/kvm/parameters/lapic
<pre class="highlight"><code>
**3. Memory Issues**
</code></pre>
Symptoms:
- Out of memory errors
- Swap usage high
- Memory leak in QEMU process</p>
<p>Diagnosis:</p>
<h1 id="check-host-memory">Check host memory</h1>
<p>free -h</p>
<h1 id="check-vm-memory">Check VM memory</h1>
<p>virsh dommemstat vm-name</p>
<h1 id="monitor-kvm-memory">Monitor KVM memory</h1>
<p>cat /sys/module/kvm/parameters/hugepages</p>
<h1 id="check-qemu-memory">Check QEMU memory</h1>
<p>ps -o pid,vsz,pmem -C qemu-system-x86_64</p>
<h1 id="check-for-ballooning">Check for ballooning</h1>
<p>virsh dominfo vm-name | grep balloon
<pre class="highlight"><code></code></pre>
Solution:
<pre class="highlight"><code># Enable memory ballooning
virt-install --balloon virtio

# Enable hugepages
echo 1 &gt; /sys/kernel/mm/hugepages/hugepages-2048kB
echo 1024 &gt; /proc/sys/vm/nr_hugepages

# Tune memory allocation
virt-install --memory 1024 --memballoc=interleave

# Limit VM memory
virsh setmem vm-name 512M

# Disable unused features
virt-install --no-usb --no-sound</code></pre></p>
<h4 id="ceph-issues">Ceph Issues</h4>
<p><strong>1. OSD Performance Problems</strong></p>
<pre class="highlight"><code>Symptoms:
- Slow I/O operations
- High latency
- OSD rebalancing constantly

Diagnosis:
ceph tell osd.* iostat
ceph osd perf

# Check OSD stats
ceph osd dump_ops osd.0

# Check PG states
ceph pg dump

# Monitor recovery
ceph -w</code></pre>
<pre class="highlight"><code>Solution:</code></pre>
<h1 id="tune-osd-configuration">Tune OSD configuration</h1>
<p>ceph config set osd osd_op_threads 2
ceph config set osd osd_max_backfills 1
ceph config set osd osd_recovery_max_active 3</p>
<h1 id="enable-bluestore">Enable BlueStore</h1>
<p>ceph config set osd osd_objectstore bluestore</p>
<h1 id="tune-memory">Tune memory</h1>
<p>ceph config set osd osd_memory_target 4G</p>
<h1 id="adjust-max-open-files">Adjust max open files</h1>
<p>ceph config set osd max_open_files 4096
<pre class="highlight"><code>
**2. PG Distribution Issues**
</code></pre>
Symptoms:
- CRUSH misplacement
- Uneven data distribution
- High latency on specific OSDs</p>
<p>Diagnosis:
ceph osd tree
ceph pg dump</p>
<h1 id="check-crush-map">Check CRUSH map</h1>
<p>ceph osd getcrushmap -o crush.map</p>
<h1 id="analyze-pg-distribution">Analyze PG distribution</h1>
<p>ceph pg dump | grep pg_num</p>
<h1 id="check-osd-utilization">Check OSD utilization</h1>
<p>ceph osd perf
<pre class="highlight"><code></code></pre>
Solution:
<pre class="highlight"><code># Adjust PG count
ceph osd pool set &lt;pool-name&gt; pg_num &lt;new-pg-count&gt;

# Rebalance cluster
ceph osd reweight-by-utilization

# Check CRUSH rules
ceph osd getcrushmap -o crush.map
crushtool -i crush.map --test --num-rep 3 --rules &lt;rule-id&gt;

# Adjust CRUSH tunables
ceph config set osd osd_max_backfills 1
ceph config set osd osd_recovery_max_active 3</code></pre></p>
<p><strong>3. Network Partition Issues</strong></p>
<pre class="highlight"><code>Symptoms:
- OSDs marked down
- Network timeouts
- Split-brain scenario

Diagnosis:
ceph -s
ceph quorum_status

# Check network connectivity
ping -c 3 &lt;mon-host&gt;

# Monitor OSD status
ceph osd tree

# Check Corosync status
corosync-cfgtool -s</code></pre>
<pre class="highlight"><code>Solution:</code></pre>
<h1 id="adjust-network-timeouts">Adjust network timeouts</h1>
<p>totem {
    token: 10000           # Increase timeout
    join: 120
}</p>
<h1 id="enable-redundant-network">Enable redundant network</h1>
<p>totem {
    interface {
        ringnumber: 1
        bindnetaddr: 192.168.2.10
        mcastport: 5405
    }
}</p>
<h1 id="check-firewall">Check firewall</h1>
<p>iptables -L -n corosync</p>
<h1 id="use-dedicated-network">Use dedicated network</h1>
<h1 id="separate-cluster-and-public-networks">Separate cluster and public networks</h1>
<pre class="highlight"><code>
### Performance Analysis

#### Profiling Techniques

**Corosync:**
```bash
# Profile with perf
perf record -e cycles,instructions -g -o perf.data corosync

# Analyze token circulation
perf report -i perf.data -s token

# Profile memory usage
perf record -e cycles -g -o mem.data corosync</code></pre>
<p><strong>Pacemaker:</strong>
<pre class="highlight"><code class="language-bash"># Profile PE calculations
time crm_simulate --simulate &gt; /dev/null

# Monitor PE frequency
grep "calculated transition" /var/log/pacemaker/pengine/*</code></pre></p>
<p><strong>QEMU:</strong>
<pre class="highlight"><code class="language-bash"># Profile QEMU
perf record -e cycles,instructions,cache-misses -g -o qemu.perf \
    qemu-system-x86_64 ...

# Profile KVM operations
perf record -e cycles,instructions,kvm:kvm_exit,kvm:kvm_entry -g -o kvm.perf \
    qemu-system-x86_64 -enable-kvm ...</code></pre></p>
<p><strong>Ceph:</strong>
<pre class="highlight"><code class="language-bash"># Profile OSD
perf record -e cycles,instructions,cache-misses -g -o osd.perf \
    -p &lt;osd-pid&gt;

# Profile network
perf record -e cycles,instructions,kvm:kvm_exit -g -o network.perf \
    tcpdump -i any 'port 6800'

# Profile I/O
iostat -x 5 -d -c &lt;rados-device&gt;</code></pre></p>
<h4 id="memory-analysis">Memory Analysis</h4>
<p><strong>Detecting Memory Leaks:</strong>
<pre class="highlight"><code class="language-bash"># Monitor process memory
watch -n 1 'ps -o pid,vsz,pmem -C corosync'

# Check for memory growth
ps -o pid,rss,vsz -C pacemaker \
    | awk '{print $2}' | sort -n

# Check for unfreed objects
valgrind --leak-check=full ./corosync

# Analyze heap usage
gdb -p corosync -batch -ex "bt"</code></pre></p>
<h4 id="concurrency-issues">Concurrency Issues</h4>
<p><strong>Pacemaker:</strong>
<pre class="highlight"><code class="language-bash"># Monitor concurrent operations
crm_mon --show-detail

# Check for deadlocks
grep "deadlock" /var/log/pacemaker/*

# Monitor transition queue
crm_simulate --show-failcounts</code></pre></p>
<p><strong>Ceph:</strong>
<pre class="highlight"><code class="language-bash"># Check for lock contention
ceph daemon --admin socket tell osd.0 dump_historic_ops

# Monitor thread pool
ceph tell osd.0 dump_ops_in_flight

# Check recovery activity
ceph -w</code></pre></p>
<h3 id="log-analysis">Log Analysis</h3>
<h4 id="understanding-log-levels">Understanding Log Levels</h4>
<p><strong>Corosync:</strong>
- <code>DEBUG</code>: Detailed diagnostic information
- <code>INFO</code>: General informational messages
- <code>WARN</code>: Warning conditions
- <code>ERROR</code>: Error conditions</p>
<p><strong>Pacemaker:</strong>
- <code>notice</code>: Information about cluster events
- <code>warning</code>: Potential issues
- <code>error</code>: Error conditions
- <code>crit</code>: Critical failures</p>
<p><strong>Ceph:</strong>
- <code>debug/10</code>: Detailed information (level 10)
- <code>debug/20</code>: More information
- <code>info</code>: General messages
- <code>warn</code>: Warning messages
- <code>err</code>: Error messages</p>
<h4 id="log-locations">Log Locations</h4>
<pre class="highlight"><code>Corosync:
/var/log/corosync/corosync.log
/var/log/corosync/debug.log
/var/log/syslog

Pacemaker:
/var/log/pacemaker/pengine/*
/var/log/pacemaker/crmd/*
/var/log/pacemaker/attrd/*

Ceph:
/var/log/ceph/ceph.log
/var/log/ceph/ceph-mon.log
/var/log/ceph/ceph-osd.*.log</code></pre>
<h4 id="log-analysis-commands">Log Analysis Commands</h4>
<p><strong>Corosync:</strong>
<pre class="highlight"><code class="language-bash"># Token analysis
grep "token" /var/log/corosync/corosync.log

# Quorum events
grep "quorum" /var/log/corosync/corosync.log

# Network issues
grep "network" /var/log/corosync/corosync.log</code></pre></p>
<p><strong>Pacemaker:</strong>
<pre class="highlight"><code class="language-bash"># Find failed resources
grep "FAILED" /var/log/pacemaker/pengine/*

# Analyze transitions
grep "calculated transition" /var/log/pacemaker/pengine/*

# Check for errors
grep "error" /var/log/pacemaker/*</code></pre></p>
<p><strong>Ceph:</strong>
<pre class="highlight"><code class="language-bash"># OSD crashes
grep "segfault" /var/log/ceph/ceph-osd.*.log

# Slow requests
grep "slow request" /var/log/ceph/ceph-osd.*.log

# Network issues
grep "timed out" /var/log/ceph/ceph-osd.*.log</code></pre></p>
<h3 id="configuration-problems">Configuration Problems</h3>
<h4 id="validation-and-testing">Validation and Testing</h4>
<p><strong>Before Applying Changes:</strong>
<pre class="highlight"><code class="language-bash"># Validate Pacemaker configuration
crm_verify -L -V

# Test with simulation
crm_simulate --live-check

# Dry-run Ceph commands
ceph tell osd.* injectargs --dry-run

# Test iSCSI configuration
gwcli.py target list</code></pre></p>
<p><strong>Rollback Procedures:</strong>
<pre class="highlight"><code class="language-bash"># Pacemaker snapshot
cibadmin --query --local &gt; cib-backup.xml

# Rollback if needed
cibadmin --replace --local --xml-file cib-backup.xml

# Restore Ceph configuration
ceph config set &lt;option&gt; &lt;previous-value&gt;</code></pre></p>
<h3 id="integration-issues">Integration Issues</h3>
<h4 id="cluster-coordination">Cluster Coordination</h4>
<p><strong>Corosync and Pacemaker:</strong>
<pre class="highlight"><code class="language-bash"># Check Corosync status from Pacemaker
crm_resource --list

# Verify quorum
crm_attribute -q -n quorum

# Check node status
pcs status nodes

# Ensure Pacemaker can communicate
crm_mon --show-detail</code></pre></p>
<p><strong>Ceph with Cluster Managers:</strong>
<pre class="highlight"><code class="language-bash"># Check if cluster manager sees Ceph
ceph -s

# Verify network connectivity
ping &lt;mon-host&gt;

# Check monitor status
ceph -w</code></pre></p>
<h4 id="storage-integration">Storage Integration</h4>
<p><strong>iSCSI Issues:</strong>
<pre class="highlight"><code class="language-bash"># Check gateway status
gwcli.py target list

# Check initiator connections
iscsiadm -m session

# Check multipath status
multipath -ll

# Reset initiator state
iscsiadm -m node logout -T &lt;target-iqn&gt; -p &lt;portal-ip&gt;
iscsiadm -m node login -T &lt;target-iqn&gt; -p &lt;portal-ip&gt; --login</code></pre></p>
<p><strong>RBD Issues:</strong>
<pre class="highlight"><code class="language-bash"># Check mapped images
rbd showmapped

# Check image status
rbd info &lt;pool&gt;/&lt;image&gt;

# Unmap and remap
rbd unmap &lt;pool&gt;/&lt;image&gt;
rbd map &lt;pool&gt;/&lt;image&gt;

# Check for stale mappings
dmesg | grep rbd</code></pre></p>
<h3 id="advanced-diagnostics">Advanced Diagnostics</h3>
<h4 id="system-level-debugging">System-Level Debugging</h4>
<pre class="highlight"><code class="language-bash"># Enable kernel debugging
echo 1 &gt; /proc/sys/kernel/sched_sched_min_granularity
echo 1 &gt; /proc/sys/kernel/khung_task_timeout_secs

# Enable KVM tracing
echo 1 &gt; /sys/module/kvm/parameters/trace_gue

# Enable Corosync tracing
corosync-cmapctl totem.trace_buffer_size 1000000

# Monitor system resources
top -b -H -d 2
vmstat 1
iostat -x 2</code></pre>
<h4 id="network-diagnostics">Network Diagnostics</h4>
<pre class="highlight"><code class="language-bash"># Check network latency
ping -i 3 -s 64 &lt;target-host&gt;

# Trace routes
traceroute -n &lt;target-host&gt;

# Check bandwidth
iperf -c 3 -t 10 &lt;target-host&gt;

# Capture packets
tcpdump -i any -w /tmp/capture.pcap host &lt;target-ip&gt;</code></pre>
<h3 id="best-practices-for-troubleshooting">Best Practices for Troubleshooting</h3>
<ol>
<li><strong>Always start with debug enabled</strong> when investigating issues</li>
<li><strong>Collect logs before clearing them</strong> - keep a complete copy</li>
<li><strong>Document the issue</strong> - note exact error messages, timestamps</li>
<li><strong>Test in isolated environment</strong> if possible</li>
<li><strong>Check configuration drift</strong> - ensure all nodes have same configuration</li>
<li><strong>Monitor system resources</strong> - CPU, memory, disk I/O, network</li>
<li><strong>Use incremental debugging</strong> - narrow down the problem step by step</li>
<li><strong>Have rollback plan</strong> - know how to quickly revert changes</li>
</ol>
<h3 id="additional-resources">Additional Resources</h3>
<ul>
<li><strong>Corosync Wiki</strong>: https://github.com/corosync/corosync/wiki/Troubleshooting</li>
<li><strong>Pacemaker Guide</strong>: https://www.clusterlabs.org/pacemaker/doc/2.0/Pacemaker_Explained/</li>
<li><strong>Ceph Troubleshooting</strong>: https://docs.ceph.com/en/latest/rados/troubleshooting/</li>
<li><strong>QEMU Debugging</strong>: https://wiki.qemu.org/Documentation/Debugging/</li>
<li><strong>Linux Performance</strong>: https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/tuning_guide/</li>
</ul>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/CrakA2/Linux_HA" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
